{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Label a big set of images can be expensive, time consuming and tedious, so that the data augmentation appears as a solution to this problem, but we have to be careful with the over fitting"
      ],
      "metadata": {
        "id": "VBIvXOZT4CAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(FILEID):\n",
        "    #FILEID es la identificación de un archivo .zip en mi drive con permisos para cualquiera que posea el ID\n",
        "    ## dicho ID se encuentra en celdas más abajo.\n",
        "    #Se carga, descomprime y finalmente guarda en la variable Data el conjunto de datos.\n",
        "    !wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='$FILEID -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=\"$FILEID -O parches.zip && rm -rf /tmp/cookies.txt\n",
        "    !unzip parches.zip\n",
        "    !dir\n",
        "\n",
        "    #Data=df.read_csv('/content/UpdatedResumeDataSet.csv')"
      ],
      "metadata": {
        "id": "cCYvscTL9Cad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJa4wLpd3758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f2af49f-4695-4e8c-efc7-da17e9df3978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-07 14:15:24--  https://docs.google.com/uc?export=download&confirm=&id=19GMUbmLY8av-Z4yU3DpkozexGXbAgNnM\n",
            "Resolving docs.google.com (docs.google.com)... 172.253.118.101, 172.253.118.113, 172.253.118.138, ...\n",
            "Connecting to docs.google.com (docs.google.com)|172.253.118.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=19GMUbmLY8av-Z4yU3DpkozexGXbAgNnM&export=download [following]\n",
            "--2025-02-07 14:15:25--  https://drive.usercontent.google.com/download?id=19GMUbmLY8av-Z4yU3DpkozexGXbAgNnM&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.175.132, 2404:6800:4003:c1c::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.175.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2422 (2.4K) [text/html]\n",
            "Saving to: ‘parches.zip’\n",
            "\n",
            "parches.zip         100%[===================>]   2.37K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-02-07 14:15:25 (39.7 MB/s) - ‘parches.zip’ saved [2422/2422]\n",
            "\n",
            "Archive:  parches.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of parches.zip or\n",
            "        parches.zip.zip, and cannot find parches.zip.ZIP, period.\n",
            "parches.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "load_data('19GMUbmLY8av-Z4yU3DpkozexGXbAgNnM')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Packages:\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img #For do Data Augmentation\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "v8FuLEmx4p2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the objetc for do DataAugmentation (Every parameter description is in the documentation)\n",
        "datage=ImageDataGenerator(rotation_range=40,zoom_range=0.2,horizontal_flip=True,fill_mode=\"nearest\",brightness_range=[0.4,1.5])"
      ],
      "metadata": {
        "id": "8QOOGmeK5O7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=load_img(\"/content/Mara.jpeg\") #Loading the image\n",
        "img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "fGlV3Grh6F59",
        "outputId": "07c71509-e1c5-4e62-ac30-ce1949d70fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Mara.jpeg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9282c4446175>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/Mara.jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Loading the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Mara.jpeg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=img_to_array(img) #Convert the image to an array\n",
        "x.shape"
      ],
      "metadata": {
        "id": "869cub946Wgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape=(1,800,600,3) #We only have 1 image"
      ],
      "metadata": {
        "id": "DPvJ2raa6iiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "coM6V_XC6whA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Running our image generator for do the data augmentation:\n",
        "i=0\n",
        "for batch in datage.flow(x,batch_size=1):\n",
        "  plt.figure(i)\n",
        "  imgplot=plt.imshow(array_to_img(batch[0]))\n",
        "  i+=1\n",
        "  if i%10==0: #For stop the generation of image\n",
        "    break\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "hNEvwKY77ECP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Genering Data Augmentation over all image of the train directoty:\n",
        "train_generator=datage.flow_from_directory(\"/content/cats_and_dogs/train\",target_size=(150,150),batch_size=32,class_mode=\"binary\") #Resolution (150x150), binary because in the image of train directory I only have 2 classes\n",
        "\n",
        "#That show me what found in the directory"
      ],
      "metadata": {
        "id": "3HqE7nkO7_sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator[0][0].shape #Images"
      ],
      "metadata": {
        "id": "9zu1iFuI9CbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator[0][1].shape #Labels"
      ],
      "metadata": {
        "id": "nUVcPG8X9JAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_generator)*32 #Now I have  2016 images (for the data aumentation) more the 2000 original images"
      ],
      "metadata": {
        "id": "D8dPiv3_HWX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting a image:\n",
        "array_to_img(train_generator[0][0][5])"
      ],
      "metadata": {
        "id": "9UWK31ks9ZbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.api._v2.keras import regularizers\n",
        "#Packages:\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "base_filtros=32 #Number of Kernels in the convolutional layers\n",
        "w_regularizer=1e-4 #weight of the relularizer\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "#First convolution layer:\n",
        "model.add(Conv2D(base_filtros,(3,3),padding=\"same\",kernel_regularizer=regularizers.l2(w_regularizer), input_shape=(150,150,3))) #put a regularizer with l2\n",
        "model.add(Activation(\"relu\")) #Put a Activation layer of type relu\n",
        "\n",
        "#Second convolution layer:\n",
        "model.add(Conv2D(base_filtros,(3,3),padding=\"same\",kernel_regularizer=regularizers.l2(w_regularizer))) #put a regularizer with l2\n",
        "model.add(Activation(\"relu\")) #Put a Activation layer of type relu\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #First MaxPooling Layer\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "#Convolution layer number 3 (Iqual but increase the number of kernels):\n",
        "model.add(Conv2D(2*base_filtros,(3,3),padding=\"same\",kernel_regularizer=regularizers.l2(w_regularizer))) #put a regularizer with l2\n",
        "model.add(Activation(\"relu\")) #Put a Activation layer of type relu\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "#Convolution layer number 4:\n",
        "model.add(Conv2D(2*base_filtros,(3,3),padding=\"same\",kernel_regularizer=regularizers.l2(w_regularizer))) #put a regularizer with l2\n",
        "model.add(Activation(\"relu\")) #Put a Activation layer of type relu\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #Second MaxPooling Layer\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "\n",
        "#Convolution layer number 5 (increase the number of kernels):\n",
        "model.add(Conv2D(4*base_filtros,(3,3),padding=\"same\",kernel_regularizer=regularizers.l2(w_regularizer))) #put a regularizer with l2\n",
        "model.add(Activation(\"relu\")) #Put a Activation layer of type relu\n",
        "\n",
        "#Convolution layer number 6:\n",
        "model.add(Conv2D(4*base_filtros,(3,3),padding=\"same\",kernel_regularizer=regularizers.l2(w_regularizer))) #put a regularizer with l2\n",
        "model.add(Activation(\"relu\")) #Put a Activation layer of type relu\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) #MaxPooling Layer Number three\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "#Classifiation (with dense layer) and Flatten:\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n"
      ],
      "metadata": {
        "id": "NdvdHH3X9q8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model:\n",
        "model.compile(metrics=[\"accuracy\"],loss=\"binary_crossentropy\",optimizer=\"rmsprop\")"
      ],
      "metadata": {
        "id": "3HVvmJ3c-Joi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model:\n",
        "history=model.fit(train_generator,epochs=5)"
      ],
      "metadata": {
        "id": "sRvGoxjN-X_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Genering Data Augmentation over all image of the train directoty:\n",
        "test_generator=datage.flow_from_directory(\"/content/cats_and_dogs/test\",target_size=(150,150),batch_size=32,class_mode=\"binary\",) #Resolution (150x150), binary because in the image of train directory I only have 2 classes\n",
        "\n",
        "#That show me what found in the directory"
      ],
      "metadata": {
        "id": "yIG9phMv-2qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "vEfwysma-jku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_generator=datage.flow_from_directory(\"/content/cats_and_dogs/validation\",target_size=(150,150),batch_size=32,class_mode=\"binary\",) #Resolution (150x150), binary because in the image of train directory I only have 2 classes\n",
        "\n",
        "#That show me what found in the directory"
      ],
      "metadata": {
        "id": "ijcxMcq95CRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator,epochs=5,validation_data=val_generator)"
      ],
      "metadata": {
        "id": "DC8koaFP5IYT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}